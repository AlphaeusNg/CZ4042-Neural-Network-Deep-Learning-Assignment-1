{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e726e0bc51bda6101498fa65e298d55",
     "grade": false,
     "grade_id": "cell-a5df181492bc4d5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Question A3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f824c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5c8f824c",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8de5fc7baf0dbbe0ae44ff5e2f33d3e2",
     "grade": false,
     "grade_id": "cell-742f6ec36e67f66e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Find the optimal number of hidden neurons for first hidden layer of the 4-layer network (3 hidden layers, output layer) designed in Question 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c699e75b7edb52e94f6605279070c695",
     "grade": false,
     "grade_id": "cell-e96803fd0366edd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "#### Plot the mean cross-validation accuracies on the final epoch for different numbers of hidden-layer neurons using a scatter plot. Limit the search space of the number of neurons to {64, 128, 256}. Continue using 5-fold cross validation on training dataset. Select the optimal number of neurons for the hidden layer. State the rationale for your selection.\n",
    "\n",
    "This might take a while to run, approximately 20 - 30 min, so plan your time carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c85ca-9a14-4d0a-b44d-814f02c0f8e1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "981c85ca-9a14-4d0a-b44d-814f02c0f8e1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "227f476ef461a471ef38af7d3f6715f8",
     "grade": false,
     "grade_id": "cell-808458412f82c806",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Firstly, we import relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0edc610-21e6-4cc7-9603-59318b961990",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b0edc610-21e6-4cc7-9603-59318b961990",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04b3385379104c8466a67ea59116fe58",
     "grade": false,
     "grade_id": "cell-03d073049be6df79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from common_utils import set_seed\n",
    "\n",
    "# setting seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e12861-4713-4914-9f4b-8a7381708243",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e8e12861-4713-4914-9f4b-8a7381708243",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1203c0efa2d363ccc72779a7511ed5b5",
     "grade": false,
     "grade_id": "cell-647b74152d4edf45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. To reduce repeated code, place your\n",
    "\n",
    "- network (MLP defined in QA1)\n",
    "- torch datasets (CustomDataset defined in QA1)\n",
    "- loss function (loss_fn defined in QA1)\n",
    "\n",
    "in a separate file called **common_utils.py**\n",
    "\n",
    "Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "The following code cell will not be marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37a1a982-de85-46de-b890-3b81f79f5887",
   "metadata": {
    "deletable": false,
    "id": "37a1a982-de85-46de-b890-3b81f79f5887",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52ed938922eb6062a33a7d047d8fc605",
     "grade": false,
     "grade_id": "import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from common_utils import MLP, CustomDataset, train_loop, test_loop\n",
    "from common_utils import split_dataset, EarlyStopper, generate_cv_folds, preprocess_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79004bd568c9f48abd1cf359cd050ab5",
     "grade": false,
     "grade_id": "cell-10b7165b0a25758f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. Perform hyperparameter tuning for the different neurons with 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c77bd18-c546-473e-8c2f-643b4281d9ba",
   "metadata": {
    "deletable": false,
    "id": "8c77bd18-c546-473e-8c2f-643b4281d9ba",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c610a779f6858f6c77f3fc6beb198dcd",
     "grade": true,
     "grade_id": "train",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, X_train_scaled, y_train2, X_val_scaled, y_val2, batch_size):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # Create datasets and data loaders for training and testing\n",
    "    train_dataset = CustomDataset(X_train_scaled, y_train2)\n",
    "    test_dataset = CustomDataset(X_val_scaled, y_val2)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize optimizer, loss function, and early stopper\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=parameters[\"learning_rate\"])\n",
    "    loss_fn = nn.BCELoss()\n",
    "    early_stopper = EarlyStopper(patience=parameters[\"patience\"], min_delta=0)\n",
    "    \n",
    "    for epoch in range(parameters[\"num_epochs\"]):\n",
    "\n",
    "        model.train()\n",
    "        start = time.time()\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "        train_losses, train_accuracies = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        end = time.time()\n",
    "\n",
    "        model.eval()\n",
    "        test_losses, test_accuracies = test_loop(test_dataloader, model, loss_fn)\n",
    "        \n",
    "        if early_stopper.early_stop(test_losses): \n",
    "            print(\"Early Stop!\")\n",
    "            times = end - start\n",
    "\n",
    "            return train_accuracies, train_losses, test_accuracies, test_losses, times\n",
    "\n",
    "    return train_accuracies, train_losses, test_accuracies, test_losses, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d13d1ff1-7242-4c3f-bcf2-c92fe0c723db",
   "metadata": {
    "deletable": false,
    "id": "d13d1ff1-7242-4c3f-bcf2-c92fe0c723db",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec4e70e2dfdc84af8c83bc858117af1f",
     "grade": true,
     "grade_id": "hyperparameter_tuning",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.691422  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.689213 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 0.683466 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.671018  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 57.4%, Avg loss: 0.679937 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.672853 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.678994  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 58.7%, Avg loss: 0.670175 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.665757 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.676680  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.659920 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.656406 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.637191  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 60.9%, Avg loss: 0.654056 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.651577 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.638804  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 62.8%, Avg loss: 0.641833 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.648198 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.627084  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 63.9%, Avg loss: 0.634117 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 0.641100 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.631516  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 64.9%, Avg loss: 0.625658 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.638589 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.654508  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.616639 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.633016 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.601403  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.608545 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 0.629964 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.619130  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.604215 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.3%, Avg loss: 0.618893 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.581911  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.594657 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 0.621841 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.537210  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.588700 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.609279 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.560530  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.576011 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.598301 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.531154  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.571232 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.596979 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.576659  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.565767 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.602534 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.549395  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.557384 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.584098 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.548295  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.553963 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.585035 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.545733  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.542859 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.575526 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.514743  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.539700 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.570921 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.490250  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.537424 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.566920 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.469620  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.525277 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.561165 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.493573  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.527081 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.562285 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.506345  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.518600 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.558336 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.521313  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.519870 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.559060 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.543918  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.514919 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.551756 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.508790  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.503188 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.546946 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.545713  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.506066 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.544872 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.460641  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.500722 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.547786 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.458734  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.492635 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.540580 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.491146  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.489840 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.548377 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.452174  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.489623 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.532835 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.507817  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.482157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.536889 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.462575  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.480854 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.533811 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.465097  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.473003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.526478 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.454859  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.470383 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.524672 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.445895  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.467458 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.529921 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.479814  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.462538 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.523619 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.457112  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.463448 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.519029 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.435526  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.462496 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.522090 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.391791  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.458175 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.522843 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.441304  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.447248 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.518108 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.428032  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.458080 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.523110 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.438624  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.445698 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.522897 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.442595  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.442237 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.513950 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.379956  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.444792 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.516797 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.475922  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.432139 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.518514 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.431048  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.429761 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.511567 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.457193  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.436253 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.510751 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.420836  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.431195 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.508431 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.449783  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.430077 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.501086 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.481627  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.418003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.510817 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.364989  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.423930 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.505479 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.376202  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.419070 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.505747 \n",
      "\n",
      "Early Stop!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.695907  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.689758 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 0.683678 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.669163  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 57.7%, Avg loss: 0.678308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.9%, Avg loss: 0.669619 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.664031  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 59.9%, Avg loss: 0.667001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.660964 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.658674  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 61.3%, Avg loss: 0.657928 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.654595 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.670998  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.649871 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.648661 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.642271  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 63.9%, Avg loss: 0.637771 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.643055 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.633696  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.635299 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.645035 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.612918  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.624231 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 0.635317 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.550203  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 65.4%, Avg loss: 0.619141 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 0.627617 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.630358  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.609338 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.620635 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.618267  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.602892 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 0.621947 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.633724  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.592384 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 0.615033 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.578861  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.587126 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.3%, Avg loss: 0.609154 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.563180  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.583683 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.602855 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.602271  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.574475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.605457 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.534280  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.564850 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.586594 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.519869  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.560686 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.583889 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.589577  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.557195 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.578662 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.525150  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.546601 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.578358 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.513230  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.545688 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.576155 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.500678  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.536526 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.573993 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.546244  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.532136 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.562775 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.460171  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.525796 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.564570 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.541671  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.527800 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.566491 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.583849  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.517302 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.559741 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.496508  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.515492 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.554488 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.516715  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.503711 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 0.551874 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.512683  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.503370 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.556129 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.489392  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.501354 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.549452 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.453588  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.493516 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.541972 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.494029  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.485860 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.539485 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.457008  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.478844 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.536099 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.456869  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.484794 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.531556 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.521405  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.479400 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.537080 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.450801  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.471017 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.533053 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.474579  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.467667 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.531671 \n",
      "\n",
      "Early Stop!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.690021  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 53.9%, Avg loss: 0.689072 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 0.687140 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.685259  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 57.2%, Avg loss: 0.678298 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 0.680193 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.666614  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.667563 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 0.669619 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.678162  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 60.7%, Avg loss: 0.660225 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 0.660908 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.645655  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.650119 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.654812 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.651660  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.640010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.645148 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.634586  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 64.3%, Avg loss: 0.630588 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 0.637084 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.609768  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.623191 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 0.626807 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.617691  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 65.3%, Avg loss: 0.616606 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 0.623172 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.591179  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.608585 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.615350 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.578874  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 67.5%, Avg loss: 0.596429 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 0.608195 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.545666  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.589806 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 0.603882 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.611498  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.585513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 0.591623 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.595478  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.577854 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.592848 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.567331  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.567666 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.585140 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.515313  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.563123 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 0.582484 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.561187  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.555637 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.581043 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.533987  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.544455 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.569225 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.535113  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.538591 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.568347 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.499569  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.525708 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.566684 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.547266  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.532657 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.564499 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.511386  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.526570 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.557412 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.522106  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.519984 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.557754 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.507377  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.512665 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.550846 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.516601  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.508990 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.551322 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.533386  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.498423 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.544956 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.487798  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.498409 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.552601 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.464705  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.499444 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.546280 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.504728  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.489419 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.540219 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.437781  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.484574 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.541986 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.493313  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.483918 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.539940 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.437772  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.477235 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.538154 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.488389  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.473620 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.536542 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.443483  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.478699 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.535025 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.446564  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.468151 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.535816 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.465322  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.462097 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.538170 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.442548  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.462014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.531878 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.510676  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.462995 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.531878 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.400875  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.451620 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.535571 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.405144  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.451730 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.527455 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.409612  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.446091 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.531310 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.407483  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.446477 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.523675 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.461118  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.447496 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.533145 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.368663  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.446817 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.526383 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.386625  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.441652 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.521852 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.454622  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.440577 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.522216 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.436565  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.439458 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.515584 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.481378  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.437144 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.518471 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.440619  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.436613 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.514239 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.415337  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.431315 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.517861 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.405621  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.424461 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.524942 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.416963  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.419623 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.527134 \n",
      "\n",
      "Early Stop!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.694443  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 52.5%, Avg loss: 0.690110 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 0.685435 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.682080  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 56.9%, Avg loss: 0.680165 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 0.674253 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.648760  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 58.9%, Avg loss: 0.670730 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.664442 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.664791  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 59.7%, Avg loss: 0.661240 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.659829 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.645724  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.653119 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 0.647153 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.665183  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 62.7%, Avg loss: 0.641165 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.642538 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.632494  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 63.4%, Avg loss: 0.633283 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 0.638772 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.644405  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 64.6%, Avg loss: 0.625053 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 0.626847 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.612999  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.616450 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.624873 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.577903  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 66.6%, Avg loss: 0.609036 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.615496 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.609396  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.598849 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.608248 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.577904  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.587107 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.600364 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.562058  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.584946 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.596841 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.582316  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 69.4%, Avg loss: 0.578262 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.596093 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.547841  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.568691 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 0.591161 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.531255  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.557060 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.586863 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.563289  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.552648 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.580921 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.542969  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 71.6%, Avg loss: 0.548119 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.574244 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.508719  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.547389 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.573526 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.498573  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.537219 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.564622 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.534367  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.529597 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.571145 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.544180  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.518997 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.556584 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.495884  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.518811 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.566863 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.516651  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.516382 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.550930 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.534233  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.512777 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.554267 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.539653  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.504084 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.552948 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.511742  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.502397 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.546537 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.483644  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.494904 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.545860 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.518487  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.489502 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.537911 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.452227  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.482469 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.536825 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.450553  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.482242 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.538025 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.459507  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.472936 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.534585 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.436588  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.474010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.533045 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.422116  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.470187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.529671 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.395986  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.465799 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.530720 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.430447  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.459463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.529276 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.481021  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.460581 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.532962 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.482082  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.452739 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.526597 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.421185  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.453014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.520140 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.443282  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.456876 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.519094 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.413567  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.446494 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.517273 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.482884  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.445639 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.516182 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.479734  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.441762 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.528047 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.542734  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.441999 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.524355 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.436280  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.441954 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.520864 \n",
      "\n",
      "Early Stop!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.696553  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 53.2%, Avg loss: 0.689684 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 0.684118 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.684995  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 56.6%, Avg loss: 0.679751 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.673832 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.663437  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 59.7%, Avg loss: 0.668460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 0.665076 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.608364  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 60.9%, Avg loss: 0.658138 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.656780 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.666662  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.649011 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.646831 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.651798  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.639495 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 0.646244 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.608776  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.633168 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.636857 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.637130  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 64.9%, Avg loss: 0.625739 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.630041 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.647836  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.616718 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.617628 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.616505  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.608630 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.612058 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.597542  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.603923 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.606692 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.576508  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.593036 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.598970 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.617706  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 69.1%, Avg loss: 0.583091 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.589883 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.599365  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.576192 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.587555 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.562280  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 70.6%, Avg loss: 0.567059 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.577869 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.561506  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.561124 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 0.573896 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.501344  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.556596 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.572475 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.537553  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.554714 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 0.562192 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.518470  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.540957 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.558319 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.480729  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.536280 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.552417 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.549813  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.534450 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.550410 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.534968  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.527431 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.550976 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.506328  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.514608 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.543282 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.508070  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.517917 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.549550 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.503128  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.506685 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.545424 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.477936  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.505189 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.544447 \n",
      "\n",
      "Early Stop!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.695292  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.686772 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 0.679481 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.684002  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 58.2%, Avg loss: 0.671283 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.2%, Avg loss: 0.666739 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.652266  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 61.1%, Avg loss: 0.654500 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 0.654832 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.669740  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.635999 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.648491 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.636891  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 64.7%, Avg loss: 0.624820 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 0.642207 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.595791  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 66.6%, Avg loss: 0.608222 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 0.630327 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.603952  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.589769 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.610335 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.560654  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 69.4%, Avg loss: 0.575055 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.610562 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.568980  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.566314 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.591816 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.537353  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.553514 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.587371 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.511227  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.533460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.584990 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.492144  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.525037 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.570982 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.517755  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.516240 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.568981 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.501596  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.500040 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.560495 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.464640  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.489827 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.557722 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.482917  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.477149 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.539628 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.451384  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.471907 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.533952 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.403132  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.457050 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.540253 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.443902  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.450111 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.525877 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.475686  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.440097 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.515797 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.402138  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.426571 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.516627 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.351038  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.428480 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.511268 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.470539  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.419271 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.519926 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.420820  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.413183 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.498071 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.393716  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.407189 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.496241 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.418919  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.389287 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.486284 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.375418  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.398446 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.494989 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.395347  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.385420 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.487146 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.310360  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.364035 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.489637 \n",
      "\n",
      "Early Stop!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.694146  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 55.1%, Avg loss: 0.685415 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.674962 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.674222  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.670444 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.663672 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.643145  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 60.2%, Avg loss: 0.659474 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 0.652749 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.662115  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.646087 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.645254 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.637084  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 64.1%, Avg loss: 0.632725 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 0.632746 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.635956  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.619913 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.627826 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.596868  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.606053 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 0.613649 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.627970  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.595496 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.610726 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.620776  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.577148 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.591665 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.558439  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.567219 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.591308 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.562079  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.547803 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.583307 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.517738  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.541689 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 0.569038 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.502942  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.526977 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.560568 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.450387  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.513087 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.556943 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.541931  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.508416 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.554942 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.482721  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.490862 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.548709 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.468704  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.487723 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.541709 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.457221  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.479442 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.548478 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.470832  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.468442 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.542722 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.480857  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.451991 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.545915 \n",
      "\n",
      "Early Stop!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.692683  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 55.2%, Avg loss: 0.684631 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.681677 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.674367  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.670126 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 0.669283 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.658163  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 60.8%, Avg loss: 0.656569 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.2%, Avg loss: 0.659563 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.688335  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 62.3%, Avg loss: 0.645613 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.648645 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.663471  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.631609 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.639026 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.621417  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 65.4%, Avg loss: 0.618268 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.633324 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.595256  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.604680 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.616237 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.611670  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.594818 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.602016 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.563221  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.574907 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.590483 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.537507  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.559123 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.579174 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.558700  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.555363 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.576193 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.578339  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.534351 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.565212 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.505615  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.523838 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.553453 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.513438  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.509033 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.542786 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.442807  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.497641 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.541579 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.487109  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.489749 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.527284 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.435996  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.473949 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.531562 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.471425  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.465087 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.529588 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.471878  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.469784 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.526041 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.374090  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.440144 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.531654 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.451836  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.435016 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.517257 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.440979  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.426513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.496511 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.370409  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.419729 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.518025 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.444578  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.407150 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.501692 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.364355  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.405301 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.507384 \n",
      "\n",
      "Early Stop!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.692191  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 53.9%, Avg loss: 0.686396 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.678519 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.682063  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.669451 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.2%, Avg loss: 0.665417 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.684799  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.657566 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.649059 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.647669  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.640653 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.641287 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.649650  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 64.6%, Avg loss: 0.625840 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.629917 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.608962  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 65.4%, Avg loss: 0.618455 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.625853 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.612632  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.596371 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.606487 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.574603  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.586273 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.606508 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.573088  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.573918 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.591489 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.588711  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.559076 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.581633 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.544369  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.533142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.560583 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.593446  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.530513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.564300 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.537550  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.520912 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.551378 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.479861  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.504247 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.547033 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.473635  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.497724 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.547475 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.443539  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.478750 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.550241 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.418141  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.473788 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.546731 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.452838  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.464026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.535340 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.460388  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.454066 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.527071 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.478338  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.443012 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.528324 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.422794  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.439142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.526929 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.425669  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.427833 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.515607 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.401903  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.414675 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.514504 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.392111  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.413048 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.509201 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.435395  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.404068 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.511405 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.402354  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.394652 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.511486 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.346033  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.393403 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.505741 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.418877  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.378040 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.520026 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.332408  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.379947 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.503339 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.410235  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.374751 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.503119 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.390167  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.365817 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.508370 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.349147  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.358664 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.502379 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.343779  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.351346 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.505617 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.308967  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.344564 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.492604 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.368275  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.343432 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.496096 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.374414  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.341259 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.496180 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.303827  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.327660 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.504425 \n",
      "\n",
      "Early Stop!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.691507  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 55.2%, Avg loss: 0.686817 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 0.678015 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.666498  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 58.6%, Avg loss: 0.671130 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 0.669229 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.662921  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.661393 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.662877 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.634998  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.646882 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.645453 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.641873  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.632579 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 0.635411 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.631911  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.613486 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.625375 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.595359  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.600902 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.608369 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.555529  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.591780 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.593777 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.523974  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.571480 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.590119 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.596844  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.559479 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.578635 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.545668  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.550560 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.568783 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.551247  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.532599 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.561457 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.546507  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.519965 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.545628 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.518003  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.503045 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.543570 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.545456  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.501275 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.541569 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.479356  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.485970 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.524022 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.466361  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.469404 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.515589 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.500235  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.467067 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.520834 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.459444  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.450120 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.509596 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.405035  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.439932 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.506699 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.435965  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.432558 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.496999 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.424648  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.423108 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.487349 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.395219  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.416573 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.484112 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.419483  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.406906 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.488191 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.405526  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.398031 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.499620 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.357944  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.398916 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.491553 \n",
      "\n",
      "Early Stop!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.692871  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.682429 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.9%, Avg loss: 0.668279 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.675542  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 59.9%, Avg loss: 0.659923 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.654590 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.656813  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 62.7%, Avg loss: 0.641419 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.4%, Avg loss: 0.641366 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.610113  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 65.4%, Avg loss: 0.619142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.631849 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.591079  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.595949 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.609158 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.544429  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.571094 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.605557 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.524044  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.547222 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.580163 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.522915  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.530085 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.569230 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.503102  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.503244 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.543937 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.478139  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.480010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.541331 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.424956  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.469753 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.532710 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.454421  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.444718 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.532111 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.351448  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.427409 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.524917 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.388321  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.408916 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.501835 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.431633  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.388097 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.498016 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.340548  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.385032 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.499703 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.389886  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.357896 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.492354 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.308019  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.359209 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.499828 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.342930  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.339397 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.488466 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.327824  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.332007 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.481392 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.308810  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.317070 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.488720 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.339090  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.312033 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.496321 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.340043  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.293881 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.480920 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.220150  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.281299 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.473919 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.274909  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.275248 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.471962 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.268764  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.262136 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.468050 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.276938  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.265924 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.466269 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.256112  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.253327 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.468403 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.218499  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.232931 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.482293 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.235961  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.233964 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.494702 \n",
      "\n",
      "Early Stop!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.694171  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.683042 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 0.669355 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.685905  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.660188 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.2%, Avg loss: 0.653139 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.663755  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.642353 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.643866 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.611456  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 65.3%, Avg loss: 0.621324 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 0.627507 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.595816  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.597059 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.617376 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.581034  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.575058 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.595506 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.547643  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.543013 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.579240 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.513849  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.521756 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 0.582684 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.494036  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.499534 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.552342 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.522066  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.473731 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.552936 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.487013  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.457551 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.534497 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.375353  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.439712 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.521966 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.393499  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.420659 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.520317 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.439734  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.399304 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.511298 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.409667  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.386719 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.505481 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.342709  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.370239 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.491844 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.374039  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.352330 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.492729 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.299601  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.334742 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.488438 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.321195  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.331465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.496555 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.323277  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.323739 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.479303 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.245724  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.307101 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.483141 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.292637  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.301103 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.489461 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.268251  [  256/ 9645]\n",
      "Train Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.283146 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.486707 \n",
      "\n",
      "Early Stop!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.691726  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 56.7%, Avg loss: 0.679317 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.679125 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.671685  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 60.4%, Avg loss: 0.657489 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.3%, Avg loss: 0.658658 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.652315  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 63.8%, Avg loss: 0.633361 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.4%, Avg loss: 0.636906 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.611585  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.615382 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.617801 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.552788  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.589889 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 0.604522 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.566631  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 70.4%, Avg loss: 0.566137 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.596179 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.517333  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.541560 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.585374 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.475585  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.516513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 0.569216 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.513844  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.490985 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.545710 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.480975  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.480259 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.542957 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.444568  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.461182 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.525885 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.422351  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.436914 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.530317 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.443834  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.427632 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.518089 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.419719  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.396281 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.531005 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.368247  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.391960 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.504936 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.373083  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.381544 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.503309 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.359219  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.363624 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.486173 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.293020  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.343959 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.512674 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.316961  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.335746 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.485415 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.379310  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.318150 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.480256 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.234269  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.309075 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.482733 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.317947  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.315144 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.490136 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.276069  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.302374 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.483458 \n",
      "\n",
      "Early Stop!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.692320  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.681063 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 0.668428 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.648393  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.660691 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 0.658494 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.662345  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.643215 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 0.637665 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.607419  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 66.0%, Avg loss: 0.616407 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 0.616892 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.595968  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.591949 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.600998 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.513833  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.569397 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.578171 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.538471  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.543049 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.558746 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.532617  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.517355 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.545382 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.509835  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.500740 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.537561 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.487869  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.476674 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.526400 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.402154  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.447059 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.527463 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.429593  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.427581 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.516090 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.417423  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.421701 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.499699 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.395919  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.392800 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.497548 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.377261  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.390438 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.498550 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.341659  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.374475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.495512 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.323756  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.355181 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.507357 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.350216  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.333838 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.477545 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.256555  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.326368 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.481467 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.329220  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.318349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.493001 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.275424  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.304162 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.490824 \n",
      "\n",
      "Early Stop!\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.692430  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 55.8%, Avg loss: 0.681617 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 0.671279 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.683387  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.662151 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 0.666205 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.658048  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.641975 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.639495 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.629497  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.619114 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 0.626548 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.595956  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.598942 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.622036 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.571575  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.570105 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.588280 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.536328  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.547374 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 0.570014 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.530431  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.522800 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.552707 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.459677  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.499982 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.559352 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.461412  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.472255 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.537094 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.487671  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.456880 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.534080 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.446609  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.433014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.504956 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.406174  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.421073 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.506332 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.378546  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.399406 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.500152 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.355465  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.378977 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.513934 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.339175  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.372085 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.498361 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.279419  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.355107 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.496706 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.357200  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.351821 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.477554 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.342655  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.330723 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.485160 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.267406  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.319285 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.485015 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.368030  [  256/ 9646]\n",
      "Train Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.308165 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.481048 \n",
      "\n",
      "Early Stop!\n"
     ]
    }
   ],
   "source": [
    "def find_optimal_hyperparameter(X_train, y_train, parameters, mode, batch_size):\n",
    "    # YOUR CODE HERE\n",
    "    # Scale data and generate cross folds\n",
    "    X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = generate_cv_folds(parameters, X_train, y_train)\n",
    "\n",
    "    cross_validation_accuracies = []\n",
    "    cross_validation_times = []\n",
    "\n",
    "    # Iterate over different numbers of hidden neurons\n",
    "    for num_hidden in parameters[\"num_neurons\"]:\n",
    "\n",
    "        # Get test and train data for each batch size\n",
    "        x_train_list = X_train_scaled_dict[num_hidden]\n",
    "        x_val_list = X_val_scaled_dict[num_hidden]\n",
    "        y_train_list = y_train_dict[num_hidden]\n",
    "        y_val_list = y_val_dict[num_hidden]\n",
    "        fold_times = []\n",
    "        fold_accuracies = []\n",
    "\n",
    "        for fold in range(parameters[\"cv_fold\"]):\n",
    "            x_train = x_train_list[fold]\n",
    "            x_val = x_val_list[fold]\n",
    "            y_train = y_train_list[fold]\n",
    "            y_val = y_val_list[fold]\n",
    "\n",
    "            # Create and train the model with the current number of hidden neurons\n",
    "            model = MLP(no_features=parameters[\"no_features\"], no_hidden=num_hidden, no_labels=parameters[\"no_labels\"])\n",
    "\n",
    "            train_accuracies, train_losses, test_accuracies, test_losses, times = train(model, x_train, y_train,\n",
    "                                                                                        x_val, y_val, batch_size)\n",
    "\n",
    "            fold_times.append(times)\n",
    "            fold_accuracies.append(test_accuracies)\n",
    "\n",
    "        cross_validation_accuracies.append(fold_accuracies)\n",
    "        cross_validation_times.append(fold_times)\n",
    "\n",
    "    cross_validation_accuracies = np.mean(np.array(cross_validation_accuracies), axis=1)\n",
    "    cross_validation_times = np.mean(np.array(cross_validation_times), axis=1)\n",
    "\n",
    "    return cross_validation_accuracies, cross_validation_times\n",
    "\n",
    "'''\n",
    "optimal_bs = 0. Fill your optimal batch size in the following code.\n",
    "'''\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Prepare dataset\n",
    "df = pd.read_csv('simplified.csv')\n",
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "df['label'].value_counts()\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_dataset(df, ['filename','label'], test_size=0.3, random_state=0)\n",
    "X_train = pd.concat([X_train, X_test])\n",
    "y_train = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "parameters = {\"num_neurons\":[64, 128, 256],\n",
    "             \"cv_fold\": 5,\n",
    "              \"no_features\": 77,\n",
    "              \"no_labels\": 1,\n",
    "              \"learning_rate\": 0.001,\n",
    "              \"batch_size\": [128],\n",
    "              \"num_epochs\": 100,\n",
    "              \"patience\": 3}\n",
    "\n",
    "num_neurons = [64, 128, 256]\n",
    "optimal_bs = 256\n",
    "cross_validation_accuracies, cross_validation_times = find_optimal_hyperparameter(X_train.to_numpy(),\n",
    "                                                                                  y_train,\n",
    "                                                                                  parameters,\n",
    "                                                                                  'num_neurons', optimal_bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0de56ab3a8b732e3ada17c55bc90a3cf",
     "grade": false,
     "grade_id": "cell-d0eceff23b1291e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. Plot the cross-validation accuracies against the number of epochs for different numbers of hidden-layer neurons. Limit the search space of the number of neurons to {64, 128, 256}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
   "metadata": {
    "deletable": false,
    "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25582e96a2b85a5ce6e0cf48a58064bd",
     "grade": true,
     "grade_id": "cell-plot",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "num_neurons = parameters[\"num_neurons\"]\n",
    "plt.figure(1)\n",
    "plt.plot(num_neurons, cross_validation_accuracies, marker = 'x', linestyle = 'None')\n",
    "plt.xticks(num_neurons)\n",
    "plt.xlabel('num neurons')\n",
    "plt.ylabel('cross-validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2024917155ea0cc8755c69415b4956cf",
     "grade": false,
     "grade_id": "part-1-3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5. Select the optimal number of neurons for the hidden layer. State the rationale for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e45a22d-9f20-441b-986b-dca35083abc3",
   "metadata": {
    "deletable": false,
    "id": "3e45a22d-9f20-441b-986b-dca35083abc3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8f1233c3ecacc38527a60e87185938b",
     "grade": false,
     "grade_id": "reason",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Number of neurons  Last Epoch Time\n0                 64         0.134216\n1                128         0.182509\n2                256         0.314089",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Number of neurons</th>\n      <th>Last Epoch Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>64</td>\n      <td>0.134216</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>128</td>\n      <td>0.182509</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>256</td>\n      <td>0.314089</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_neurons = 256\n",
    "reason = \"Selected because it had the highest cross-validation accuracy on last epoch.\"\n",
    "# YOUR CODE HERE\n",
    "df = pd.DataFrame({'Number of neurons': num_neurons,\n",
    "                   'Last Epoch Time': cross_validation_times\n",
    "                  })\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf2dc5e-91d5-49dc-a05f-b9318f3371a7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ebf2dc5e-91d5-49dc-a05f-b9318f3371a7",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c609ceb4ecc2dac0684b1da17f44daa",
     "grade": false,
     "grade_id": "cell-302503e166f647c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "6. Plot the train and test accuracies against training epochs with the optimal number of neurons using a line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd1a17fa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 600x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.plot(range(1,len(train_acc)+1),train_acc, label='Training Acc')\n",
    "plt.plot(range(1,len(test_acc)+1),test_acc,label='Test Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cz4042",
   "language": "python",
   "name": "cz4042"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}